{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c709f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "messages = [ {\"role\": \"system\", \"content\": \"You are a intelligent assistant.\"} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf7b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_chatgpt(_messages, prompt, _model=\"gpt-3.5-turbo\"):\n",
    "\n",
    "# with only the current clip as information\n",
    "    chat = openai.ChatCompletion.create(\n",
    "        model=_model, messages= [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "#   with all the context in the same video clip $TOO LARGE TOKEN SIZE\n",
    "#   _messages.append({\"role\": \"user\", \"content\": prompt},)\n",
    "#   chat = openai.ChatCompletion.create(\n",
    "#       model=_model, messages=_messages\n",
    "#   )\n",
    "\n",
    "    reply = chat.choices[0].message.content\n",
    "#     _messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "508d03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQA(data_file):\n",
    "    QA = {}\n",
    "    \n",
    "    f = open(data_file)\n",
    "    \n",
    "    data = json.load(f)\n",
    "    for video_id in data:\n",
    "        messages = [ {\"role\": \"system\", \"content\": \n",
    "              \"You are a intelligent assistant.\"} ]\n",
    "        QA[video_id] = {}\n",
    "        QA[video_id]['annotation_qa'] = []\n",
    "        QA[video_id]['summary_qa'] = []\n",
    "        video = data[video_id]\n",
    "        \n",
    "        i = 0\n",
    "        for item in video['narrations']:\n",
    "            if i == 20:\n",
    "                break;\n",
    "            prompt = get_prompt(' start_time: ' + str(item['time']) \n",
    "                                + ' end_time: ' + str(item['_end_time']) \n",
    "                                + ' description: ' + str(item['text']))\n",
    "            QA[video_id]['annotation_qa'].append(chat_with_chatgpt(messages, prompt))\n",
    "            i += 1\n",
    "        \n",
    "        i = 0\n",
    "        for item in video['summaries']:\n",
    "            if i == 20:\n",
    "                break;\n",
    "            prompt = get_prompt(' start_time: ' + str(item['start_time']) \n",
    "                                + ' end_time: ' + str(item['end_time']) \n",
    "                                + ' description: ' + str(item['text']))\n",
    "            QA[video_id]['summary_qa'].append(chat_with_chatgpt(messages, prompt))\n",
    "            i += 1\n",
    "\n",
    "    return QA\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1fefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(data_location):\n",
    "    return \"\"\"\n",
    "        Your task is to create a comprehensive set of question-and-answer pairs for each time slot of an egocentric video.Create a final answer to the given questions using the provided document excerpts(in no particular order) as references. ALWAYS include a \"SOURCES\" section in your answer including only the minimal set of sources needed to answer the question. If you are unable to answer the question, simply state that you do not know. Do not attempt to fabricate an answer and leave the SOURCES section empty.\n",
    "        ---------\n",
    "        QUESTION: What  is the purpose of ARPA-H?\n",
    "        =========\n",
    "        Content: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more.\n",
    "        Source: 1-32\n",
    "        Content: While we’re at it, let’s make sure every American can get the health care they need. \\n\\nWe’ve already made historic investments in health care. \\n\\nWe’ve made it easier for Americans to get the care they need, when they need it. \\n\\nWe’ve made it easier for Americans to get the treatments they need, when they need them. \\n\\nWe’ve made it easier for Americans to get the medications they need, when they need them.\n",
    "        Source: 1-33\n",
    "        Content: The V.A. is pioneering new ways of linking toxic exposures to disease, already helping  veterans get the care they deserve. \\n\\nWe need to extend that same care to all Americans. \\n\\nThat’s why I’m calling on Congress to pass legislation that would establish a national registry of toxic exposures, and provide health care and financial assistance to those affected.\n",
    "        Source: 1-30\n",
    "        =========\n",
    "        FINAL ANSWER: The purpose of ARPA-H is to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more.\n",
    "        SOURCES: 1-32\n",
    "        ---------\n",
    "        QUESTION: {question}\n",
    "        =========\n",
    "        {summaries}\n",
    "        =========\n",
    "        FINAL ANSWER:\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    You are given the description of a video clip, and the data has a start time, end time, and description of the clip.\n",
    "    You must generate a set of question answer pairs for this video clip.\n",
    "    Ask the question \"When does (your detailed description of the object) appear?\" for every physical object (including things like keys, spoon, and phone but does not including non-physical object such as a conversation or a movement) that appears in the description.\n",
    "    And the answer must be in the format: start_time: , end_time: .\n",
    "    If there is no physical object in the description, answer \"no objects\"\n",
    "    Here is the format:\\n Q:\\n A:\\n’.\n",
    "    \n",
    "    Now complete your task given the start time, end time, and context of the video as the following: %s0\n",
    "    \"\"\" % data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eeb27d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = generateQA('out.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14775cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ego4DQA.json', 'w') as wf:\n",
    "    json.dump(QA, wf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
