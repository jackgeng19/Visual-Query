{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c709f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "messages = [ {\"role\": \"system\", \"content\": \"You are a intelligent assistant.\"} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf7b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_chatgpt(_messages, prompt, _model=\"gpt-3.5-turbo\"):\n",
    "\n",
    "# with only the current clip as information\n",
    "    chat = openai.ChatCompletion.create(\n",
    "        model=_model, messages= [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "#   with all the context in the same video clip $TOO LARGE TOKEN SIZE\n",
    "#   _messages.append({\"role\": \"user\", \"content\": prompt},)\n",
    "#   chat = openai.ChatCompletion.create(\n",
    "#       model=_model, messages=_messages\n",
    "#   )\n",
    "\n",
    "    reply = chat.choices[0].message.content\n",
    "#     _messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "508d03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQA(data_file):\n",
    "    QA = {}\n",
    "    \n",
    "    f = open(data_file)\n",
    "    \n",
    "    data = json.load(f)\n",
    "    for video_id in data:\n",
    "        messages = [ {\"role\": \"system\", \"content\": \n",
    "              \"You are a intelligent assistant.\"} ]\n",
    "        QA[video_id] = {}\n",
    "        QA[video_id]['annotation_qa'] = []\n",
    "        QA[video_id]['summary_qa'] = []\n",
    "        video = data[video_id]\n",
    "        \n",
    "        i = 0\n",
    "        for item in video['narrations']:\n",
    "            if i == 20:\n",
    "                break;\n",
    "            prompt = get_prompt(' start_time: ' + str(item['time']) \n",
    "                                + ' end_time: ' + str(item['_end_time']) \n",
    "                                + ' description: ' + str(item['text']))\n",
    "            QA[video_id]['annotation_qa'].append(chat_with_chatgpt(messages, prompt))\n",
    "            i += 1\n",
    "        \n",
    "        i = 0\n",
    "        for item in video['summaries']:\n",
    "            if i == 20:\n",
    "                break;\n",
    "            prompt = get_prompt(' start_time: ' + str(item['start_time']) \n",
    "                                + ' end_time: ' + str(item['end_time']) \n",
    "                                + ' description: ' + str(item['text']))\n",
    "            QA[video_id]['summary_qa'].append(chat_with_chatgpt(messages, prompt))\n",
    "            i += 1\n",
    "\n",
    "    return QA\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1fefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(data_location):\n",
    "    return \"\"\"\n",
    "        Your task is to create a comprehensive set of question-and-answer(QA) pairs for each time slot of an egocentric video. Your data input would be start time, end time, and the description of event during the time period. The questions and answers should be designed to facilitate machine learning and test understanding for computers, covering key concepts and important information presented in the video. Create a final QA pair to the given questions using the provided document excerpts(in no particular order) as references. If you are unable to answer the question you are given or unable to generate a question, simply state that you do not know. Do not attempt to fabricate an answer and leave the Question and Answer section empty.\n",
    "        ---------\n",
    "        Description: '#C C drops the vegetable on the chair with other vegetables'\n",
    "        =========\n",
    "        Q: What does C do?\n",
    "        A: C drops the vegetable on the chair with other vegetables\n",
    "\n",
    "        Q: What does C drop?\n",
    "        A: the vegetable\n",
    "\n",
    "        Q: Where does C drop the vegetable?\n",
    "        A: on the chair\n",
    "        =========\n",
    "        Here is the result format:\\n Q:\\n A:\\n’. + start_time + end_time\n",
    "\n",
    "        Now complete your task given the start time, end time, and description of the video as the following: %s0\n",
    "\n",
    "        \"\"\" % data_location\n",
    "\n",
    "    # \"\"\"\n",
    "    # You are given the description of a video clip, and the data has a start time, end time, and description of the clip.\n",
    "    # You must generate a set of question answer pairs for this video clip.\n",
    "    # Ask the question \"When does (your detailed description of the object) appear?\" for every physical object (including things like keys, spoon, and phone but does not including non-physical object such as a conversation or a movement) that appears in the description.\n",
    "    # And the answer must be in the format: start_time: , end_time: .\n",
    "    # If there is no physical object in the description, answer \"no objects\"\n",
    "    # Here is the format:\\n Q:\\n A:\\n’.\n",
    "    \n",
    "    # Now complete your task given the start time, end time, and context of the video as the following: %s0\n",
    "    # \"\"\" % data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eeb27d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = generateQA('out.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14775cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ego4DQA.json', 'w') as wf:\n",
    "    json.dump(QA, wf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
