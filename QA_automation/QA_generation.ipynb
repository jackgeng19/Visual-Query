{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21c709f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "messages = [ {\"role\": \"system\", \"content\": \"You are a intelligent assistant.\"} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdf7b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_chatgpt(_messages, prompt, _model=\"gpt-3.5-turbo\"):\n",
    "\n",
    "# with only the current clip as information\n",
    "    chat = openai.ChatCompletion.create(\n",
    "        model=_model, messages= [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "#   with all the context in the same video clip $TOO LARGE TOKEN SIZE\n",
    "#   _messages.append({\"role\": \"user\", \"content\": prompt},)\n",
    "#   chat = openai.ChatCompletion.create(\n",
    "#       model=_model, messages=_messages\n",
    "#   )\n",
    "\n",
    "    reply = chat.choices[0].message.content\n",
    "#     _messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "508d03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQA(data_file):\n",
    "    QA = {}\n",
    "    \n",
    "    f = open(data_file)\n",
    "    \n",
    "    data = json.load(f)\n",
    "    for video_id in data:\n",
    "        messages = [ {\"role\": \"system\", \"content\": \n",
    "              \"You are a intelligent assistant.\"} ]\n",
    "        QA[video_id] = {}\n",
    "        QA[video_id]['annotation_qa'] = []\n",
    "        QA[video_id]['summary_qa'] = []\n",
    "        video = data[video_id]\n",
    "        \n",
    "        i = 0\n",
    "        for item in video['narrations']:\n",
    "            if i == 10:\n",
    "                break;\n",
    "            prompt = get_prompt(' start_time: ' + str(item['time']) \n",
    "                                + ' end_time: ' + str(item['_end_time']) \n",
    "                                + ' description: ' + str(item['text']))\n",
    "            QA[video_id]['annotation_qa'].append(chat_with_chatgpt(messages, prompt))\n",
    "            i += 1\n",
    "        \n",
    "        i = 0\n",
    "        for item in video['summaries']:\n",
    "            if i == 10:\n",
    "                break;\n",
    "            prompt = get_prompt(' start_time: ' + str(item['start_time']) \n",
    "                                + ' end_time: ' + str(item['end_time']) \n",
    "                                + ' description: ' + str(item['text']))\n",
    "            QA[video_id]['summary_qa'].append(chat_with_chatgpt(messages, prompt))\n",
    "            i += 1\n",
    "\n",
    "    return QA\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e1fefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(data_location):\n",
    "    return \"\"\"\n",
    "        Your task is to create a comprehensive set of question-and-answer(QA) pairs for each time slot of an egocentric video. Your data input would be start time, end time, and the description of event during the time period. The questions and answers should be designed to facilitate machine learning and test understanding for computers, covering key concepts and important information presented in the video. Create a final QA pair to the given questions using the provided document excerpts(in no particular order) as references. If you are unable to answer the question you are given or unable to generate a question, simply state that you do not know. Do not attempt to fabricate an answer and leave the Question and Answer section empty.\n",
    "        ---------\n",
    "        Here is an example of the format of the data input and its QA pairs:\\n\n",
    "        start_time: 0.0 end_time: 0.0420572\n",
    "        description: '#C C drops the vegetable on the chair with other vegetables'\n",
    "        =========\n",
    "        Q: What does C do?\n",
    "        A: C drops the vegetable on the chair with other vegetables. <0.0 - 0.0420572>\n",
    "\n",
    "        Q: What does C drop?\n",
    "        A: the vegetable. <0.0 - 0.0420572>\n",
    "\n",
    "        Q: Where does C drop the vegetable?\n",
    "        A: on the chair. <0.0 - 0.0420572>\n",
    "        =========\n",
    "        Please format your results as follows: 'Q: <question> + '\\n' +  A: <answer>.' + <'start_time' - 'end_time'> + '\\n'\n",
    "\n",
    "        Now complete your task given the start time, end time, and description of the video as the following: %s\n",
    "\n",
    "        \"\"\" % data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eeb27d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA = generateQA('out.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d14775cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ego4DQA.json', 'w') as wf:\n",
    "    json.dump(QA, wf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
